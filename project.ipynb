{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sqlite3\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define the number of samples\n",
    "num_samples = 50000\n",
    "\n",
    "\n",
    "customer_ids = np.arange(num_samples)\n",
    "\n",
    "\n",
    "ages = np.random.randint(18, 71, size=num_samples)\n",
    "\n",
    "#Gender\n",
    "genders = np.random.choice(['Male', 'Female', 'Other'], size=num_samples, p=[0.48, 0.48, 0.04])\n",
    "\n",
    "\n",
    "marital_statuses = np.random.choice(['Single', 'Married', 'Divorced', 'Widowed', 'Separated'], size=num_samples, p=[0.45, 0.4, 0.1, 0.02, 0.03])\n",
    "\n",
    "#Education Level\n",
    "education_levels = np.random.choice(['High School', 'Associate Degree', 'Bachelor Degree', 'Master Degree', 'Doctorate'], size=num_samples, p=[0.3, 0.2, 0.3, 0.15, 0.05])\n",
    "\n",
    "#Geographic Information\n",
    "states = ['Florida', 'Michigan', 'New York', 'Virginia', 'Ohio', 'Illinois', 'California', 'Oregon', 'Washington', 'Pennsylvania']\n",
    "geographic_info = np.random.choice(states, size=num_samples)\n",
    "\n",
    "#Occupation\n",
    "occupations = ['Entrepreneur', 'Manager', 'Salesperson', 'Engineer', 'Teacher', 'Healthcare', 'IT Professional', 'Clerk', 'Technician', 'Consultant']\n",
    "occupation = np.random.choice(occupations, size=num_samples)\n",
    "\n",
    "#Income Level\n",
    "income_level = np.random.normal(loc=60000, scale=20000, size=num_samples).astype(int)\n",
    "income_level = np.clip(income_level, 20000, 150000)\n",
    "\n",
    "#Behavioral Data\n",
    "behavioral_data = np.random.normal(loc=30, scale=10, size=num_samples).astype(int)\n",
    "behavioral_data = np.clip(behavioral_data, 5, 120)\n",
    "\n",
    "#Purchase History\n",
    "start_date = datetime(2019, 12, 1)\n",
    "end_date = datetime(2023, 12, 1)\n",
    "\n",
    "#Generate random dates between dates\n",
    "purchase_history = [start_date + timedelta(days=random.randint(0, (end_date - start_date).days)) for _ in range(num_samples)]\n",
    "\n",
    "#Insurance Products Owned\n",
    "insurance_products = np.random.randint(1, 6, size=num_samples)\n",
    "\n",
    "#Policy Type\n",
    "policy_types = ['Individual', 'Family', 'Group']\n",
    "policy_type = np.random.choice(policy_types, size=num_samples, p=[0.5, 0.3, 0.2])\n",
    "\n",
    "#Customer Preferences\n",
    "customer_preferences = np.random.randint(1, 6, size=num_samples)\n",
    "\n",
    "#Preferred Communication Channel\n",
    "communication_channels = ['Email', 'Phone', 'Mail', 'Text', 'Mobile App', 'Chat']\n",
    "preferred_communication = np.random.choice(communication_channels, size=num_samples)\n",
    "\n",
    "#Preferred Contact Time\n",
    "contact_times = ['Morning', 'Afternoon', 'Evening', 'Anytime', 'Weekends']\n",
    "preferred_contact_time = np.random.choice(contact_times, size=num_samples)\n",
    "\n",
    "#Preferred Language\n",
    "languages = ['English', 'French', 'German', 'Spanish', 'Hindi', 'Mandarin']\n",
    "preferred_language = np.random.choice(languages, size=num_samples)\n",
    "\n",
    "#Segmentation Group\n",
    "segmentation_groups = ['Segment1', 'Segment2', 'Segment3', 'Segment4', 'Segment5']\n",
    "segmentation_group = np.random.choice(segmentation_groups, size=num_samples)\n",
    "\n",
    "# Create df\n",
    "data = pd.DataFrame({\n",
    "    'Customer ID': customer_ids,\n",
    "    'Age': ages,\n",
    "    'Gender': genders,\n",
    "    'Marital Status': marital_statuses,\n",
    "    'Education Level': education_levels,\n",
    "    'Geographic Information': geographic_info,\n",
    "    'Occupation': occupation,\n",
    "    'Income Level': income_level,\n",
    "    'Behavioral Data': behavioral_data,\n",
    "    'Purchase History': purchase_history,\n",
    "    'Insurance Products Owned': insurance_products,\n",
    "    'Policy Type': policy_type,\n",
    "    'Customer Preferences': customer_preferences,\n",
    "    'Preferred Communication Channel': preferred_communication,\n",
    "    'Preferred Contact Time': preferred_contact_time,\n",
    "    'Preferred Language': preferred_language,\n",
    "    'Segmentation Group': segmentation_group\n",
    "})\n",
    "\n",
    "#Map Insurance Products Owned\n",
    "policy_names = ['policy1', 'policy2', 'policy3', 'policy4', 'policy5']\n",
    "mapped_policy_names = [policy_names[i-1] for i in insurance_products]\n",
    "data['Insurance Products Owned'] = mapped_policy_names\n",
    "\n",
    "# 20. Map Insurance Products Owned to the values [1, 3, 2, 5, 4] for calculations\n",
    "insurance_mapping = {1: 1, 2: 3, 3: 2, 4: 5, 5: 4}\n",
    "mapped_insurance_products = [insurance_mapping[i] for i in insurance_products]\n",
    "\n",
    "# 21. Calculate Coverage Amount using mapped values\n",
    "coverage_amount = (\n",
    "    500 * data['Income Level'] / 1000 +\n",
    "    1000 * data['Age'] +\n",
    "    20000 * np.array(mapped_insurance_products) +\n",
    "    np.random.normal(0, 10000, size=num_samples)  # Adding noise\n",
    ")\n",
    "\n",
    "# 22. Calculate Premium Amount\n",
    "premium_amount = (\n",
    "    0.05 * coverage_amount +\n",
    "    3000 * data['Education Level'].map({'High School': 1, 'Associate Degree': 2, 'Bachelor Degree': 3, 'Master Degree': 4, 'Doctorate': 5}) +\n",
    "    1000 * data['Customer Preferences'] +\n",
    "    np.random.normal(0, 5000, size=num_samples)  # Adding noise\n",
    ")\n",
    "\n",
    "# Assign to DataFrame\n",
    "data['Coverage Amount'] = coverage_amount.astype(int)\n",
    "data['Premium Amount'] = premium_amount.astype(int)\n",
    "\n",
    "# Display the first few rows\n",
    "df = data\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('customerdba')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#Customers Table\n",
    "cursor.execute('''\n",
    "DROP TABLE IF EXISTS Customers;\n",
    "''')\n",
    "cursor.execute('''\n",
    "DROP TABLE IF EXISTS CustomerPolicies;\n",
    "''')\n",
    "cursor.execute('''\n",
    "DROP TABLE IF EXISTS CustomerPreferences;\n",
    "''')\n",
    "cursor.execute('''\n",
    "DROP TABLE IF EXISTS InsuranceProducts;\n",
    "''')\n",
    "cursor.execute('''\n",
    "CREATE TABLE Customers (\n",
    "    CustomerID INTEGER PRIMARY KEY,\n",
    "    Age INTEGER,\n",
    "    Gender TEXT,\n",
    "    MaritalStatus TEXT,\n",
    "    EducationLevel TEXT,\n",
    "    GeographicInformation TEXT,\n",
    "    Occupation TEXT,\n",
    "    IncomeLevel REAL,\n",
    "    BehavioralData TEXT\n",
    ");\n",
    "''')\n",
    "\n",
    "#CustomerPolicies Table\n",
    "cursor.execute('''\n",
    "CREATE TABLE CustomerPolicies (\n",
    "    PolicyID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    CustomerID INTEGER,\n",
    "    PurchaseHistory TEXT,\n",
    "    InsuranceProductsOwned TEXT,\n",
    "    CoverageAmount REAL,\n",
    "    PremiumAmount REAL,\n",
    "    PolicyType TEXT,\n",
    "    FOREIGN KEY (CustomerID) REFERENCES Customers(CustomerID),\n",
    "    FOREIGN KEY (InsuranceProductsOwned) REFERENCES InsuranceProducts(ProductName)\n",
    ");\n",
    "''')\n",
    "\n",
    "#CustomerPreferences Table\n",
    "cursor.execute('''\n",
    "CREATE TABLE CustomerPreferences (\n",
    "    PreferenceID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    CustomerID INTEGER,\n",
    "    CustomerPreferences1 INTEGER,\n",
    "    PreferredCommunicationChannel TEXT,\n",
    "    PreferredContactTime TEXT,\n",
    "    PreferredLanguage TEXT,\n",
    "    SegmentationGroup TEXT,\n",
    "    FOREIGN KEY (CustomerID) REFERENCES Customers(CustomerID)\n",
    ");\n",
    "''')\n",
    "\n",
    "#InsuranceProducts Table\n",
    "cursor.execute('''\n",
    "CREATE TABLE InsuranceProducts (\n",
    "    ProductName TEXT PRIMARY KEY,\n",
    "    ProductDescription TEXT\n",
    ");\n",
    "''')\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df['Coverage Amount'] = pd.to_numeric(df['Coverage Amount'])\n",
    "df['Premium Amount'] = pd.to_numeric(df['Premium Amount'])\n",
    "df['Purchase History'] = pd.to_datetime(df['Purchase History'], errors='coerce').dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for _, row in df.iterrows():\n",
    "    # Insert into Customers table\n",
    "    cursor.execute('''\n",
    "    INSERT INTO Customers (CustomerID, Age, Gender, MaritalStatus, EducationLevel, GeographicInformation, Occupation, IncomeLevel, BehavioralData)\n",
    "    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    ''', (\n",
    "        row['Customer ID'], row['Age'], row['Gender'], row['Marital Status'], row['Education Level'],\n",
    "        row['Geographic Information'], row['Occupation'], float(row['Income Level']), row['Behavioral Data']\n",
    "    ))\n",
    "\n",
    "    # Insert into InsuranceProducts table (if needed) before inserting into CustomerPolicies\n",
    "    # Ensure InsuranceProductsOwned in CustomerPolicies references ProductName\n",
    "    insurance_products = {\n",
    "        'policy1': 'Comprehensive health insurance covering a wide range of medical needs',\n",
    "        'policy2': 'Affordable health insurance with flexible coverage options',\n",
    "        'policy3': 'Premium health insurance offering extensive benefits and services',\n",
    "        'policy4': 'Reliable health insurance designed for long-term healthcare security',\n",
    "        'policy5': 'Specialized health insurance tailored to meet unique individual needs'\n",
    "    }\n",
    "\n",
    "    # Check and insert insurance product based on row['Insurance Products Owned']\n",
    "    if row['Insurance Products Owned'] in insurance_products:\n",
    "        product_name = row['Insurance Products Owned']\n",
    "        product_description = insurance_products[product_name]\n",
    "\n",
    "        cursor.execute('''\n",
    "        INSERT OR IGNORE INTO InsuranceProducts (ProductName, ProductDescription)\n",
    "        VALUES (?, ?)\n",
    "        ''', (product_name, product_description))\n",
    "\n",
    "    # Insert into CustomerPolicies table\n",
    "    cursor.execute('''\n",
    "    INSERT INTO CustomerPolicies (CustomerID, PurchaseHistory, InsuranceProductsOwned, CoverageAmount, PremiumAmount, PolicyType)\n",
    "    VALUES (?, ?, ?, ?, ?, ?)\n",
    "    ''', (\n",
    "        row['Customer ID'], row['Purchase History'], row['Insurance Products Owned'],\n",
    "        row['Coverage Amount'], row['Premium Amount'], row['Policy Type']\n",
    "    ))\n",
    "\n",
    "    # Insert into CustomerPreferences table\n",
    "    cursor.execute('''\n",
    "    INSERT INTO CustomerPreferences (CustomerID, CustomerPreferences1, PreferredCommunicationChannel, PreferredContactTime, PreferredLanguage, SegmentationGroup)\n",
    "    VALUES (?, ?, ?, ?, ?, ?)\n",
    "    ''', (\n",
    "        row['Customer ID'], row['Customer Preferences'], row['Preferred Communication Channel'], row['Preferred Contact Time'],\n",
    "        row['Preferred Language'], row['Segmentation Group']\n",
    "    ))\n",
    "# Commit the changes and close the connection\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "incomeGrouping = \"\"\"\n",
    "SELECT\n",
    "    CustomerID, Age, Gender, IncomeLevel,MaritalStatus,EducationLevel,\n",
    "    CASE\n",
    "        WHEN IncomeLevel > (SELECT AVG(IncomeLevel) FROM Customers) THEN 'Above Average'\n",
    "        ELSE 'Below Average'\n",
    "    END AS Income_Group\n",
    "FROM Customers;\"\"\"\n",
    "\n",
    "iG = pd.read_sql_query(incomeGrouping, conn)\n",
    "iG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "highValueCustomers = \"\"\"\n",
    "SELECT c.Age,c.Gender,c.MaritalStatus,c.Occupation,c.IncomeLevel,cp.PolicyType,cp.CoverageAmount,cp.PremiumAmount,p.PreferredCommunicationChannel,p.PreferredLanguage\n",
    "FROM\n",
    "    Customers c\n",
    "JOIN\n",
    "    CustomerPolicies cp ON c.CustomerID = cp.CustomerID\n",
    "JOIN\n",
    "    CustomerPreferences p ON c.CustomerID = p.CustomerID\n",
    "ORDER BY\n",
    "    cp.CoverageAmount DESC, c.IncomeLevel DESC\n",
    "LIMIT 10;\"\"\"\n",
    "hVC = pd.read_sql_query(highValueCustomers, conn)\n",
    "hVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sg = \"\"\"SELECT p.SegmentationGroup, cp.PolicyType, COUNT(cp.PolicyID) AS policyCount\n",
    "FROM CustomerPreferences p\n",
    "JOIN CustomerPolicies cp ON p.CustomerID = cp.CustomerID\n",
    "GROUP BY p.SegmentationGroup, cp.PolicyType\"\"\"\n",
    "sg = pd.read_sql_query(sg, conn)\n",
    "sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "    c.CustomerID AS \"Customer ID\",\n",
    "    c.Age,\n",
    "    c.Gender,\n",
    "    c.MaritalStatus AS \"Marital Status\",\n",
    "    c.EducationLevel AS \"Education Level\",\n",
    "    c.GeographicInformation AS \"Geographic Information\",\n",
    "    c.Occupation,\n",
    "    c.IncomeLevel AS \"Income Level\",\n",
    "    c.BehavioralData AS \"Behavioral Data\",\n",
    "    cp.PurchaseHistory AS \"Purchase History\",\n",
    "    cp.InsuranceProductsOwned AS \"Insurance Products Owned\",\n",
    "    cp.CoverageAmount AS \"Coverage Amount\",\n",
    "    cp.PremiumAmount AS \"Premium Amount\",\n",
    "    cp.PolicyType AS \"Policy Type\",\n",
    "    cr.CustomerPreferences1 AS \"Customer Preferences\",\n",
    "    cr.PreferredCommunicationChannel AS \"Preferred Communication Channel\",\n",
    "    cr.PreferredContactTime AS \"Preferred Contact Time\",\n",
    "    cr.PreferredLanguage AS \"Preferred Language\",\n",
    "    cr.SegmentationGroup AS \"Segmentation Group\"\n",
    "FROM\n",
    "    Customers c\n",
    "LEFT JOIN\n",
    "    CustomerPolicies cp ON c.CustomerID = cp.CustomerID\n",
    "LEFT JOIN\n",
    "    CustomerPreferences cr ON c.CustomerID = cr.CustomerID;\n",
    "'''\n",
    "\n",
    "\n",
    "df1 = pd.read_sql_query(query, conn)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "age_distribution= df['Age'].value_counts().sort_index()\n",
    "plt.figure(figsize=(12,6))\n",
    "age_distribution.plot(kind='bar', color='green')\n",
    "plt.title('Age distribution of customers')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('number of customers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "gender_distribution=df['Gender'].value_counts().sort_index()\n",
    "plt.figure(figsize=(12,6))\n",
    "gender_distribution.plot(kind='bar', color='blue')\n",
    "plt.title('Gender distribution of customers')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('number fo customers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "marital_status_distribution=df['Marital Status'].value_counts().sort_index()\n",
    "plt.figure(figsize=(12,6))\n",
    "marital_status_distribution.plot(kind='bar', color='black')\n",
    "plt.title('Marital Status distribution of customers')\n",
    "plt.xlabel('Marital Status')\n",
    "plt.ylabel('number fo customers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "education_distribution=df['Education Level'].value_counts().sort_index()\n",
    "plt.figure(figsize=(12,6))\n",
    "education_distribution.plot(kind='bar', color='red')\n",
    "plt.title('Educaiton level distribution of customers')\n",
    "plt.xlabel('Education level')\n",
    "plt.ylabel('Number of customers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "geo_distribution=df['Geographic Information'].value_counts().sort_index()\n",
    "plt.figure(figsize=(12,6))\n",
    "geo_distribution.plot(kind='bar')\n",
    "plt.title('Geographic distribution of customers')\n",
    "plt.xlabel('Geographic information')\n",
    "plt.ylabel('number of customers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "age_distribution= df['Occupation'].value_counts().sort_index()\n",
    "plt.figure(figsize=(12,6))\n",
    "age_distribution.plot(kind='bar', color='green')\n",
    "plt.title('Occupation distribution of customers')\n",
    "plt.xlabel('Occupation')\n",
    "plt.ylabel('number of customers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "age_distribution= df['Behavioral Data'].value_counts().sort_index()\n",
    "plt.figure(figsize=(12,6))\n",
    "age_distribution.plot(kind='bar', color='yellow')\n",
    "plt.title('Behavioral Data distribution of customers')\n",
    "plt.xlabel('Behavioral Data')\n",
    "plt.ylabel('number of customers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "numerical_columns = ['Age', 'Income Level', 'Behavioral Data', 'Coverage Amount', 'Premium Amount']\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df[numerical_columns].corr(), annot=True, cmap='coolwarm')\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='Age', y='Premium Amount', hue='Gender', data=df)\n",
    "plt.title(\"Age vs Premium Amount by Gender\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='Age', y='Coverage Amount', hue='Gender', data=df)\n",
    "plt.title(\"Age vs Coverage Amount by Gender\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Conclusion\n",
    "\n",
    "# In summary, this exploratory data analysis (EDA) provided insights into the customer segmentation dataset.\n",
    "# Visualizations revealed the distribution of key demographic and behavioral characteristics, including age, gender, marital status, education level, geographic location, occupation, and behavioral data.\n",
    "# These visualizations highlight potential customer segments based on these characteristics, laying the groundwork for more advanced segmentation techniques like clustering or classification algorithms.\n",
    "# Further analysis could focus on correlations between these features and customer spending habits, product preferences, or other relevant metrics to refine segmentation strategies and improve targeted marketing efforts.\n",
    "# The identified customer segments can inform business decisions around product development, marketing campaigns, and customer relationship management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "clean_df = df.copy()\n",
    "\n",
    "# Ensure 'Purchase History' is in datetime format and convert it to number of days\n",
    "clean_df['Purchase History'] = pd.to_datetime(clean_df['Purchase History'], errors='coerce')\n",
    "start_date = datetime(2019, 12, 1)\n",
    "clean_df['Purchase History'] = (clean_df['Purchase History'] - start_date).dt.days\n",
    "\n",
    "# Features and Targets\n",
    "X = clean_df.drop(['Customer ID', 'Coverage Amount', 'Premium Amount'], axis=1)\n",
    "y_coverage = clean_df['Coverage Amount']\n",
    "y_premium = clean_df['Premium Amount']\n",
    "\n",
    "# One-Hot Encoding for Categorical Variables\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Coverage Amount\n",
    "X_train_cov, X_test_cov, y_train_cov, y_test_cov = train_test_split(\n",
    "    X_scaled, y_coverage, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Premium Amount\n",
    "X_train_prem, X_test_prem, y_train_prem, y_test_prem = train_test_split(\n",
    "    X_scaled, y_premium, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "linear_reg_cov = LinearRegression()\n",
    "random_forest_cov = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "\n",
    "linear_reg_prem = LinearRegression()\n",
    "random_forest_prem = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "\n",
    "# Train models for Coverage Amount\n",
    "linear_reg_cov.fit(X_train_cov, y_train_cov)\n",
    "random_forest_cov.fit(X_train_cov, y_train_cov)\n",
    "\n",
    "# Train models for Premium Amount\n",
    "linear_reg_prem.fit(X_train_prem, y_train_prem)\n",
    "random_forest_prem.fit(X_train_prem, y_train_prem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Coverage Amount Prediction\n",
    "print(\"\\n--- Coverage Amount Prediction ---\")\n",
    "y_pred_cov_lr = linear_reg_cov.predict(X_test_cov)\n",
    "mse_cov_lr = mean_squared_error(y_test_cov, y_pred_cov_lr)\n",
    "r2_cov_lr = r2_score(y_test_cov, y_pred_cov_lr)\n",
    "print(f\"Linear Regression - MSE: {mse_cov_lr:.2f}, R²: {r2_cov_lr:.4f}\")\n",
    "\n",
    "y_pred_cov_rf = random_forest_cov.predict(X_test_cov)\n",
    "mse_cov_rf = mean_squared_error(y_test_cov, y_pred_cov_rf)\n",
    "r2_cov_rf = r2_score(y_test_cov, y_pred_cov_rf)\n",
    "print(f\"Random Forest - MSE: {mse_cov_rf:.2f}, R²: {r2_cov_rf:.4f}\")\n",
    "\n",
    "# Storing results\n",
    "results_cov = {\n",
    "    \"Linear Regression\": {\"MSE\": mse_cov_lr, \"R²\": r2_cov_lr},\n",
    "    \"Random Forest\": {\"MSE\": mse_cov_rf, \"R²\": r2_cov_rf},\n",
    "}\n",
    "\n",
    "# Premium Amount Prediction\n",
    "print(\"\\n--- Premium Amount Prediction ---\")\n",
    "y_pred_prem_lr = linear_reg_prem.predict(X_test_prem)\n",
    "mse_prem_lr = mean_squared_error(y_test_prem, y_pred_prem_lr)\n",
    "r2_prem_lr = r2_score(y_test_prem, y_pred_prem_lr)\n",
    "print(f\"Linear Regression - MSE: {mse_prem_lr:.2f}, R²: {r2_prem_lr:.4f}\")\n",
    "\n",
    "y_pred_prem_rf = random_forest_prem.predict(X_test_prem)\n",
    "mse_prem_rf = mean_squared_error(y_test_prem, y_pred_prem_rf)\n",
    "r2_prem_rf = r2_score(y_test_prem, y_pred_prem_rf)\n",
    "print(f\"Random Forest - MSE: {mse_prem_rf:.2f}, R²: {r2_prem_rf:.4f}\")\n",
    "\n",
    "# Storing results\n",
    "results_prem = {\n",
    "    \"Linear Regression\": {\"MSE\": mse_prem_lr, \"R²\": r2_prem_lr},\n",
    "    \"Random Forest\": {\"MSE\": mse_prem_rf, \"R²\": r2_prem_rf},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Residual Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.residplot(x=y_test_cov, y=y_pred_cov_rf, lowess=True, line_kws={\"color\": \"red\"})\n",
    "plt.title(\"Residual Plot  (Coverage Amount)\")\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance for Linear Regression (Coverage Amount)\n",
    "coef_cov_lr = pd.Series(\n",
    "    linear_reg_cov.coef_, index=X_encoded.columns\n",
    ").sort_values(ascending=False)\n",
    "print('\\n')\n",
    "print(\"--- Feature Importance (Coefficients) for Linear Regression (Coverage Amount) ---\")\n",
    "print(coef_cov_lr.head(10))\n",
    "\n",
    "# Feature Importance for Random Forest\n",
    "rf_cov = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "rf_cov.fit(X_train_cov, y_train_cov)\n",
    "importances_cov = pd.Series(rf_cov.feature_importances_, index=X_encoded.columns)\n",
    "print('\\n')\n",
    "print(\"--- Feature Importance for Coverage Amount ---\")\n",
    "print(importances_cov.sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Use the predictions from Random Forest for residual plot\n",
    "y_pred_prem = y_pred_prem_rf  # Replace with y_pred_prem_lr if you want Linear Regression predictions\n",
    "\n",
    "# Residual Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.residplot(x=y_test_prem, y=y_pred_prem, lowess=True, line_kws={\"color\": \"red\", \"lw\": 2})\n",
    "plt.title(\"Residual Plot (Premium Amount)\")\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance for Linear Regression (Premium Amount)\n",
    "coef_prem_lr = pd.Series(\n",
    "    linear_reg_prem.coef_, index=X_encoded.columns\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "print('\\n')\n",
    "print(\"--- Feature Importance (Coefficients) for Linear Regression (Premium Amount) ---\")\n",
    "print(coef_prem_lr.head(10))\n",
    "\n",
    "# Feature Importance for Random Forest\n",
    "rf_prem = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "rf_prem.fit(X_train_prem, y_train_prem)\n",
    "importances_prem = pd.Series(rf_prem.feature_importances_, index=X_encoded.columns)\n",
    "print('\\n')\n",
    "print(\"--- Feature Importance for Premium Amount ---\")\n",
    "print(importances_prem.sort_values(ascending=False).head(10))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
